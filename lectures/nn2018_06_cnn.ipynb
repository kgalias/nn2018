{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<big><big><big><big><big><big>Sieci neuronowe 2018</big></big></big></big></big></big>\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<big><big><big><big><big>Sieci konwolucyjne</big></big></big></big></big>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<id=tocheading><big><big><big><big>Spis treści</big></big></big></big>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "from bokeh.io import gridplot, output_file, show\n",
    "from bokeh.plotting import figure, output_notebook\n",
    "from bkcharts import Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image inclusion\n",
    "<img src=\"nn_figures/\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci konwolucyjne\n",
    "1. wykorzystują __konwolucje__ zamiast mnożenia macierzy w co najmniej jednej z warstw\n",
    "  * czym są _konwolucje_?\n",
    "  * czym jest _pooling_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noecognitron (Fukushima, 1980)\n",
    "<img src=\"nn_figures/neocognitron.png\" width=\"100%\"> ['O'Reilly]\n",
    "1. na wejściu jest __retina__ odpowiedzialna za odbiór obrazu\n",
    "2. hierarchicznie ułożnone warstwy __S__ i __C__\n",
    "  * __S__-warstwy (S jak simple) odpowiedzialne za ekstrakcję cech\n",
    "    * zmienne wejścia modyfikowane poprzez uczenie\n",
    "    * po zakończeniu uczenia każda s-komórka staje się _ekstraktorem_ pewnej konkretnej cechy w polu widzenia (selektywnie na nią odpowiada)\n",
    "      * uczenie odpowiada wyborowi wykrywanej cechy\n",
    "    * cechy bardziej lokalne są wykrywane bliżej wejścia modelu, te bardziej globalne później\n",
    "  * __C__-warstwy (C jak complex) \n",
    "    * pozwalają na korekcję błędów translacji na wejściu\n",
    "    * wejścia do C-komórek z ekstraktorów w warstwach S są ustalone i niezmienne\n",
    "    * każda C-komórka dostaje wejście z grupy S-komórek wykrywających __tą samą__ cechę ale niewiele różniących się pozycjach - zapewnia inwariantność na translacje\n",
    "    * C-komórka jest aktywowana jeśli co najmniej jedna S-komórka wykryła cechę\n",
    "3. warstwy S i C przypominają komórki w układzie widzenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nn_figures/neocognitron2.gif\" width=\"80%\"> [ScholarPedia, Fukushima]\n",
    "1. Sieć uczy się w procesie __samo-organizacji__\n",
    "  * tylko S-komórki mają modyfikowane wagi\n",
    "  * __winner-take-all__ wśród komórek w małym okreslonym obszarze (kolumnie) tylko jedna staje się zwycięzcą i jest aktywowana\n",
    "    * połączenia zwycięzcy są wzmacniane\n",
    "    * siła wzmocnienia jest proporcjonalna do aktywacji\n",
    "    * na początku wszystkie połączenia są bardzo słabe\n",
    "    * po jakimś czasie S-komórki uczą się rozpoznawać pewne wzorce\n",
    "  * wszystkie komórki z otoczenia zwycięzcy podążają za nim\n",
    "<img src=\"nn_figures/neocognitron4.gif\" width=\"100%\"> [ScholarPedia, Fukushima]\n",
    "2. Neocognitron osiąga na zbiorze MNIST błąd rzędu 2.5%\n",
    "3. Nauczanie jest niezależne dla każdej warstwy\n",
    "  * istotne stają się wielkości komórek C i S, co utrudnia uczenie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet5 (LeCun 1998)\n",
    "<img src=\"nn_figures/lenet5.pdf\" width=\"100%\">[LeCun NIPS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucje\n",
    "1. dla dwu-wymiarowych obrazów $I$ można zdefiniować 2-wymiarowe kernele $K$ tak, że __dyskretna__ konwolucja będzie zdefiniowana jako\n",
    "$$S(i,j)=(I*K)(i,j)=\\sum_m\\sum_nI(m,n)K(i-m,j-n)$$\n",
    "2. konwolucje są komutatywne, skąd\n",
    "$$S(i,j)=(K*I)(i,j)=\\sum_m\\sum_nI(i-m,j-n)K(m,n)$$\n",
    "  * ten opis jest dla obrazów bardziej oczywisty \n",
    "  * zwykle implementowany implementowany będzie schemat korelacji\n",
    "  $$S(i,j)=(I*K)(i,j)=\\sum_m\\sum_nI(i+m,j+n)K(m,n)$$\n",
    "  dający ten sam wynik\n",
    "  * macierz kernela jest _rzadka_: zerowa wszędzie poza polami leżącymi na obrazie\n",
    "3. co dają konwolucje?\n",
    "  * __rzadkie interakcje__\n",
    "    * w sieciach warstwowych każdy element wyjściowy jest połączony z każdym wejściowym przez jakiś parametr\n",
    "    * kernel jest __mniejszy__ niż wejście\n",
    "    * zwiększa wydajność\n",
    "    * te same cechy są wykrywane w różnych miejscach\n",
    "    * w głębokich sieciach neurony w głębszych warstwach współpracują z większymi obszarami wejścia\n",
    "  * __współdzielenie parametrów__\n",
    "    * w modelach warstwowych każda waga jest użyta __dokładnie raz__ przy liczeniu wyjścia\n",
    "    * w sieci konwolucyjnej każda waga kernela jest użyta dla __każdego__ elementu wejścia (ew. poza obszarami na brzegu)\n",
    "      * zamiast uczyć zestawu wag dla każdego wejścia, uczony jest __jeden__ zestaw\n",
    "  * __równoważne reprezentacje__\n",
    "    * utworzone reprezentacje $f$ stają się odporne na translacje $t$, bo $f(t(x))=t(f(x))$\n",
    "    * kernel wykrywający brzegi będzie do zastosowania w różnych miejscach obrazu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "<img src=\"nn_figures/cnn.pdf\" width=\"100%\"> [Goodfellow et al.]\n",
    "1. typowa warstwa sieci CNN składa się z\n",
    "  * szeregu __konwolucji__ tworzących liniowe aktywacje\n",
    "  * __nieliniowych aktywacji__ dla wykrywania (detekcji) cech (features)\n",
    "  * modyfikacji przez __pooling__\n",
    "2. pooling __zastępuje__ warstość w danym miejscu pewną statystyką dla obszaru wokół\n",
    "  * __max pooling__ zwraca maksymalną wartość dla pewnego prostokątnego obszaru\n",
    "    * każde pole tego obszaru może odpowiadać nieco różnej wykrytej cesze\n",
    "  * __average pooling__ zwraca średnią\n",
    "  * __L2 norm pooling__ normą kwadratową dla prostokątnego obszaru\n",
    "  * __weighted pooling__ ważoną średnią odległość od piksela w centrum obszaru\n",
    "3. max pooling wprowadza pewną inwariantność na translację\n",
    "  * niewielkie przesunięcie wejścia może zmienić tylko niewielką część wyjścia\n",
    "  * także pewną inwariantność na powiększenie\n",
    "  * pooling zmniejsza rozmiar przetwarzanego obszaru\n",
    "    * w kolejnych warstwach przetwarzane są cechy wyższego poziomu\n",
    "    * także efektywniejsze obliczeniowo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucje w modelach sieci neuronowych\n",
    "1. konwolucja z __jednym__ kernelem wykrywa tylko __jedną__ cechę (feature), chociaż w wielu miejscach\n",
    "  * w sieciach neuronowych potrzebujemy wykrywać __wiele różnych__ cech w wielu miejscach\n",
    "2. wejściowy obraz składa się zwykle z wektorów obserwacji w każdym punkcie\n",
    "  * np. obraz RGB\n",
    "  * wejściem do konwolucji w kolejnej warstwie są wyjścia konwolucji poprzedniej \n",
    "  * dla obrazów wejścia i wyjścia są tensorami 3-D\n",
    "    * jeden indeks to kanał\n",
    "    * dwa indeksy podają współrzędne\n",
    "  * w rzeczywistości 4-D tensory: jeszcze indeks pozycji w batchu\n",
    "3. __stride__ określa przesunięcie ponad niektórymi cechami obrazu wejściowego\n",
    "  * konwolucja ze stride jest równoważna pełnej konwolucji z downsamplingiem bezpośrednio później\n",
    "4. __padding__ pozwala na kontrolę szerokości obrazu w kolejnych warstwach\n",
    "  * bez paddingu obraz zmniejsza się co najmniej o piksel na warstwę\n",
    "  * bez paddingu albo obraz szybko się zmniejsza albo potrzebne jest użycie małych kerneli\n",
    "    * oba rozwiązania są niedobre\n",
    "5. możliwe alternatywy\n",
    "  * __no (valid) padding__ i pixele kernela __nie mogą __ wychodzić poza obszar obrazu\n",
    "    * wszystkie piksele wyjścia są funkcją __tej samej__ liczby pikseli wejścia\n",
    "    * każda kolejna warstwa zmniejsza się\n",
    "    \n",
    "    <img width=\"150px\" src=\"nn_figures/gif/no_padding_no_strides.gif\"><img width=\"150px\" src=\"nn_figures/gif/no_padding_strides.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "    * liczba pikseli wyjściowych wynosi (dla $s=1$) $$o=(i-k)+2p+1$$\n",
    "    * dla $s>1$ liczba pikseli wyjściowych $$o=\\left\\lfloor\\frac{i-k}{s}\\right\\rfloor+1$$\n",
    "  * __same (half) padding__ zapewnia tyle dodanych pikseli by warstwy __nie zmniejszały__ się\n",
    "    * może być dowolna liczba warstw konwolucji\n",
    "    * piksele blisko brzegu wpływają na mniej pikseli wyjściowych\n",
    "    \n",
    "    <img width=\"150px\" src=\"nn_figures/gif/same_padding_no_strides.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "    * liczba pikseli wyjściowych (dla $s=1, k=2n+1, p=\\lfloor{}k/2\\rfloor$) to $$o=i+2\\lfloor{}k/2\\rfloor-(k-1)=i+2n-2n=i$$\n",
    "  * __full padding__ gdzie dodane jest tyle zer, by każdy piksel obrazu był odwiedzony tą samą liczbę razy\n",
    "    * każdy __wyjściowy__ piksel blisko brzegu jest funkcją mniejszej liczby pikseli wejściowych\n",
    "    \n",
    "    <img width=\"150px\" src=\"nn_figures/gif/full_padding_no_strides.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "    * liczba pikseli wyjściowych (dla $p=k-1, s=1$) to $$o=i+2(k-1)-(k-1)=i+(k-1)$$\n",
    "    \n",
    "    <img width=\"150px\" src=\"nn_figures/gif/padding_strides.gif\"><img width=\"150px\" src=\"nn_figures/gif/padding_strides_odd.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "  * w ogólnym przypadku liczba wyjsciowych to $$o=\\left\\lfloor\\frac{i+2p-k}{s}\\right\\rfloor+1$$\n",
    "6. zwykle optymalne rozwiązanie leży gdzieś między _valid_ a _same_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "1. warstwy pooling zapewniają pewne niewielkie inwariancje na translacje wejścia\n",
    "2. __max pooling__ \n",
    "  * dzieli wejście na patche\n",
    "    * zwykle __nie__ nakładające się\n",
    "  * wybraniu maksymalnej wartości\n",
    "3. pooling nie wykorzystuje paddowania, a więc $$o=\\left\\lfloor\\frac{i-k}{s}\\right\\rfloor+1$$\n",
    "  * a więc tak samo jak konwolucje bez paddingu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dekonwolucje\n",
    "1. a gdybyśmy chcieli odzyskać widzialne obrazy z głębokich reprezentacji?\n",
    "  * prostym rozwiązaniem jest mnożenie przez __transpozycję__ macierzy konwolucji\n",
    "  * modele auto-enkoderów, RBM, itp.\n",
    "2. jest to jednak trochę bardziej złożone niż w modelach warstwowych\n",
    "3. konwolucje __transponowane__\n",
    "\n",
    "  <img width=\"150px\" src=\"nn_figures/gif/no_padding_no_strides.gif\"><img width=\"150px\" src=\"nn_figures/gif/no_padding_no_strides_transposed.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "  * konwolucja $3\\times3$ nad wejsciem $4\\times4$ bez paddingu ($p=0$) i jednostkowym stridem ($s=1$)\n",
    "  * równoważne konwolucji $3\\times3$ nad wejściem $2\\times2$ wypadowane z każdej strony pasem $2$ pikseli ($p=2$) z jednostkowym strajdem (???!!!???) ($s=1$)\n",
    "  * jednak narożne piksele wejścia wpływają __jedynie__ na naróżne piksele odtwarzanego obrazu\n",
    "    * paddowanie ma wymiar $p=k-1$\n",
    "    * stąd wymiar wyjściowy to $o'=i'+(k-1)$\n",
    "  * takie transponowane konwolucje zresztą jedynie odtwarzają __kształt__, a nie ma tu żadnej pewności odtwarzania wejścia\n",
    "4. konwolucje strajdowane __cząstkowo__ (_ang_. __fractionally__)\n",
    "  * czy możemy sobie wyobrazić sytuację z $s<1$??\n",
    "  \n",
    "  <img width=\"150px\" src=\"nn_figures/gif/no_padding_strides_transposed.gif\"><img width=\"150px\" src=\"nn_figures/gif/padding_strides_transposed.gif\">[Dumoulin, Visin, arXiv:1603.07285]\n",
    "  * wyjście będzie miało wymiar $$o'=s(i'-1)+k$$ gdzie $p'=k-1$ a rozszerzone wejście $i'$ jest uzyskane przez dodanie $s-1$ pasów zer miedzy wszystkimi zerami/kolumnami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucje rozmyte (dilated)\n",
    "1. albo __atrous__ z francuskiego ___a trous___ (_z dziurami_)\n",
    "2. rozmyciu ulega kernel przez dodanie spacji pomiędzy elementy jądra\n",
    "  * dodawane jest $d-1$ rzędów/wierszy spacji, gdzie $d=1$ odpowiada konwolucji nierozmytej\n",
    "  * rozmycie kernela sztucznie zwiększa jego wymiar do $$k'=k+(k-1)(d-1)$$\n",
    "  <img width=\"150px\" src=\"nn_figures/gif/dilation.gif\">[Dumoulin, Visin, arXiv:1603.07285]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie sieci CNN\n",
    "1. każdy kernel jest odpowiedzialny za wykrywanie pewnej cechy\n",
    "2. okazuje się, że wsteczna propagacja jest __wystarczająca__\n",
    "  * konwolucja\n",
    "  * wsteczna propagacja od wyjścia do wag\n",
    "  * wsteczna propagacja od wyjscia do wejścia\n",
    "  \n",
    "  są wystarczające dla nauczenie dowolnej sieci CNN z propagacją wprzód\n",
    "  \n",
    "3. __bias__ jest także elementem sieci CNN\n",
    "  * w sieciach warstwowych typowy bias jest związany z każdym neuronem\n",
    "  * w CNN każdy bias jest typowo związany z każdym kanałem\n",
    "    * możliwe jest rozróżnienie biasu dla różnych położeń obrazu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet: Alex net\n",
    "<img src=\"nn_figures/imagenet.pdf\" width=\"100%\">[Krizhevsky, Sutskever, Hinton NIPS]\n",
    "1. Konkurs ILSVRC'2010 (ImageNet Large-Scale Visual Recognition Challenge)\n",
    "  * oryginalny zbiór danych ma ponad 22 miliony obrazów etykietowanych ponad 22 tysiącami klas\n",
    "  * zbiór danych konkursu to 1.2 miliona obrazów z 1000 różnych klas\n",
    "  * 50 tysięcy walidacyjnych, 150 tysięcy testowych\n",
    "  * obrazy różnych rozdzielczości przeskalowane i wycięte do $256\\times256$\n",
    "    * w końcowym uczeniu użyte obrazy $224\\times224$\n",
    "  * dwie miary błędów\n",
    "    * __top-1__ binarna miara prawidłowa/nieprawidłowa\n",
    "    * __top-5__ że prawidłowa etykieta __jest/nie jest__ wśród 5-ciu zaproponowanych\n",
    "  * problem uczony na danych __jedynie__ z odjętą średnią dla każdego piksela/kanału\n",
    "2. wyniki\n",
    "  * top-1 37.5\\% błędów\n",
    "  * top-5 17.0\\% błędów\n",
    "    * jedna z wersji osiągnęła 15.3\\% w top-5\n",
    "    * drugi najlepszy miał w top-5 26.2\\% błędów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architektura\n",
    "<img src=\"nn_figures/imagenet.pdf\" width=\"100%\">[Krizhevsky, Sutskever, Hinton NIPS]\n",
    "1. 8 warstw: 5 konwolucyjnych i 3 warstwowe\n",
    "1. ostatnia warstwa jest softmaxem o wymiarze 1000 zwracającym szanse dla kazdej z klas\n",
    "2. kolejne warstwy konwolucyjne\n",
    "  * pierwsza $224\\times224\\times3$ ma 96 kerneli o wymiarach $11\\times11\\times3$ i stride $s=4$\n",
    "  * druga na obrazie $55\\times55\\times48$ ma 256 kerneli $5\\times5\\times48$\n",
    "    * __uwaga__ warstwy konwolucyjne zostały zaimplementowane na dwóch GPU (Nvidia GTX-580 z 3GB pamięci każda)\n",
    "    * skutkuje to __podziałem__ kanałów na dwa procesory\n",
    "    * kernele w warstwie 3 biorą wejście z __wszystkich__ kerneli warstwy 2\n",
    "    * jednak kernele warstwy 4 biorą wejście __jedynie__ z kerneli na __tym samym__ GPU\n",
    "    * to powoduje zmianę głębokości\n",
    "    * ten schemat ulepszył wyniki po ok. 1.5\\% dla uzytych błędów\n",
    "  * trzecia warstwa konwolucji na __dwóch__ obrazach $27\\times27\\times128$ używa 384 kerneli $3\\times3\\times256$\n",
    "  * czwarta ma 384 kernele $3\\times3\\times192$ na obrazie $13\\times13\\times192$\n",
    "  * piąta ma 256 kerneli $3\\times3\\times192$ na obrazie $13\\times13\\times192$ dając dwa obrazy $13\\times13\\times128$\n",
    "3. warstwy max-pooling użyte są po pierwszej, po drugiej i po piątej konwolucji\n",
    "  * wbrew zwyczajowi warstwy te są __nakładające__ się, co minimalnie zmniejsza wymiar\n",
    "4. po piatej warstwie następują dwie warstwy po 4096 neuronów każda\n",
    "  * warstwy też podzielone pomiedzy dwa GPU\n",
    "5. łącznie sieć ma ponad 60 milionów parametrów\n",
    "  * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "1. w trakcie uczenia sieć overfitowała\n",
    "  * mimo ponad miliona przykładów\n",
    "2. augmentacja danych\n",
    "  * z oryginalnych $256\\times256$ wybrane losowo obrazy $224\\times224$\n",
    "  * także losowe poziome odbicia\n",
    "  * obrazy generowane na bierząco\n",
    "  * 2048 razy więcej obrazów\n",
    "3. w trakcie testowania\n",
    "  * wybrane obrazy z rogów\n",
    "  * obraz centralny\n",
    "  * odbicia poziome każdego z nich\n",
    "  * uśrednione $10$ znalezionych predykcji\n",
    "4. modyfikacja intensywności kanałów RGB\n",
    "  * PCA na kanałach\n",
    "  * do każdego kanału dodana wielokrotność znalezionej składowej głównej przemnożonej przez warstość własną przez wartość losową z rokładu normalnego\n",
    "    * do każdego pksela $I_{xy}=[I_{xy}^R,I_{xy}^G,I_{xy}^B]$ dodana wartość $$[p_1,p_2,p_3][\\alpha_1\\lambda_1,\\alpha_2\\lambda_2,\\alpha_3\\lambda_3]^T$$ gdzie $p_i,\\lambda_i$ to $i$-te wektory i składowe główne macierzy kowariancji $x\\times3$ wartosci RGB\n",
    "  * ten schemat minimalizuje wpływ oświetlenia\n",
    "  * polepszył on wyniki top-1 o ponad 1\\%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "1. użyty w pierwszych warstwach sieci z pełnymi połączeniami\n",
    "2. użyte $p=0.5$\n",
    "3. wymagało dwukrotnie dłuższego czasu nauczania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nauczone filtry\n",
    "<img src=\"nn_figures/imagenet-filters.pdf\" width=\"100%\">[Krizhevsky, Sutskever, Hinton NIPS]\n",
    "1. model nauczył się szeregu różnych filtrów\n",
    "2. w warstwie pierwszej\n",
    "  * GPU1 nauczył się filtrów praktycznie nie zawierających kolorów, za to posiadających cechy wykrywające krawędzie i zwroty\n",
    "  * GPU2 wykrywał bloby kolorów\n",
    "  * według autorów następowało to zawsze __bez względu__ na inicjalizację\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obrazy\n",
    "<img src=\"nn_figures/imagenet-images.pdf\" width=\"100%\">[Krizhevsky, Sutskever, Hinton NIPS]\n",
    "\n",
    "1. po lewej obrazy i ich klasyfikacje przez model\n",
    "2. po prawej obrazy testowe w pierwszej kolumnie i po pięć obrazów najbliższych w euklidesowej przestrzeni ostatniej warstwy ukrytej\n",
    "3. usunięcie którejkolwiek warstwy środkowej powodowało spadek skuteczności o ponad 2%\n",
    "  * głębokość gra rolę"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 recognition [cs232n.stanford.edu](http://cs231n.stanford.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 (Simonyan, Zisserman, ImageNet'2014)\n",
    "<img src=\"nn_figures/vgg16.png\" width=\"100%\"> [Simonyan, Zisserman, 2014]\n",
    "1. Krizhevsky et al. zwracali uwagę, że głębokość gra rolę\n",
    "2. jednocześnie wydawało się, że konwolucje muszą być dużę na początku, by obejmować większy semantycznie obszar\n",
    "## Architektura\n",
    "3. jeśli jednak weźmiemy __mały__ wymiar kernela, to przy małym paddingu można utrzymać wymiar\n",
    "  * $k=3$, $p=\\lfloor3/2\\rfloor$ i wtedy $$o=i+2\\lfloor k/2\\rfloor-(k-1)=i+2\\left\\lfloor\\frac{2n+1}{2}\\right\\rfloor-(2n+1-1)=i+n-n=i$$\n",
    "  * to pozwala na dużą liczbę warstw\n",
    "4. kernel $3\\times3$ jest najmniejszym pozwalającym na wykrywanie krawędzi i pojęć lewy/prawy, góra/dół\n",
    "5. wejście stałe $224\\times224$ z odjętymi średnimi pikseli (jak w AlexNet)\n",
    "6. architektura na rysunku ma 16 warstw konwolucyjnych (wszystkie $3\\times3$) w blokach\n",
    "  1. $3\\times3\\times64$, ReLU, $3\\times3\\times64$, ReLU, max-pool\n",
    "  2. $3\\times3\\times128$, ReLU, $3\\times3\\times128$, ReLU, max-pool\n",
    "  3. $3\\times3\\times256$, ReLU, $3\\times3\\times256$, ReLU, $3\\times3\\times256$, ReLU,  max-pool\n",
    "  4. $3\\times3\\times256$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU,  max-pool\n",
    "  5. $3\\times3\\times256$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU,  max-pool\n",
    "  6. FF 4096, FF 4096, FF 1000, softmax\n",
    "7. rozszerzona sieć z 19 warstwami\n",
    "  1. $3\\times3\\times64$, ReLU, $3\\times3\\times64$, ReLU, max-pool\n",
    "  2. $3\\times3\\times128$, ReLU, $3\\times3\\times128$, ReLU, max-pool\n",
    "  3. $3\\times3\\times256$, ReLU, $3\\times3\\times256$, ReLU, $3\\times3\\times256$, ReLU,  max-pool\n",
    "  4. $3\\times3\\times256$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU,  max-pool\n",
    "  5. $3\\times3\\times256$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU, $3\\times3\\times512$, ReLU, max-pool\n",
    "  6. FF 4096, FF 4096, FF 1000, softmax\n",
    "7. w jeszcze innej konfiguracji z 16 warstwami ostatnie konwolucje w dwóch ostatnich blokach (4. i 5.) były o wymiarach $1\\times1$\n",
    "  * konwolucje $1\\times1$ w zasadzie nie wprowadzają żadnej informacji o sąsiedztwie\n",
    "  * jednak zwiększają nieliniowość __nie__ zmieniając wymiaru\n",
    "## Uczenie\n",
    "1. sieć ma większą liczbę parametrów niż AlexNet \n",
    "  * ok. 140 milionów\n",
    "2. uczenie SGD z momentum rozpoczęło się ze współczynnikiem uczenia $0.01$ by być zmniejszonym gdy spadek na zbiorze walidacyjnym zanikł\n",
    "3. uczenie zostało zatrzymane po 370 tysiącach iteracji\n",
    "4. model był uczony na dwóch rozdzielczościach: 256 i 384 pikseli\n",
    "## Wyniki\n",
    "1. wersje 16- i 19-warstwowe osiągały do 24.8% w top-1 i 7.5% w top-5\n",
    "2. wersja złożona z 2 modeli osiągała 23.7% oraz 6.8% (7.32% w złożonym modelu)\n",
    "3. to wyniki porównywalne ze zwycięzcą GoogleNet, który miał 6.67%\n",
    "4. a model vgg-16 jest znacznie prostszy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogleNet (Szegedy et al.)\n",
    "<img src=\"nn_figures/inception-naive.pdf\" width=\"50%\"><img src=\"nn_figures/inception-reduction.pdf\" width=\"50%\">[Szegedy et al. 2015]\n",
    "1. ten model rozwinął głębokość\n",
    "2. cały model zbudowany jest z modułów __inception__\n",
    "  * wszystkie konwolucje mają wymiary $5\\times5$, $3\\times3$ i $1\\times1$\n",
    "  * wymiary podyktowane wygodą, by łatwiej się zgadzały granice\n",
    "  * każdy moduł jest połączeniem wielu konwolucji wraz z poolingiem\n",
    "    * ekstrakcja cech na wielu poziomach jednocześnie\n",
    "    * $1\\times1$ pozwala na konwolucje nie przestrzenną (spatial), ale tzw. __cross-channel__\n",
    "3. dla zapewnienia inwariantności na translacje uzywamy powtarzalnych bloków\n",
    "  * blok ma analizować korelacje w warstwie i grupować je z dużą korelacją\n",
    "  * te tworzą elementy kolejnej warstwy\n",
    "  * klastry skoncentrowane w jednym regionie mogą być łatwo przetwarzane przez konwolucje $1\\times1$ dla zwiększenia nieliniowości\n",
    "  * bardziej rozległe cechy muszą być pokryte przez kernele o większym wymiarze\n",
    "  * dodatkowy pooling też daje zyski\n",
    "  * tak wygląda _naiwny_ moduł inception\n",
    "4. poważnym problemem tak poustawianych jeden na drugim modułów będzie coraz większe rozrzucenie przestrzenne cech wyższego rzędu\n",
    "  * to sugeruje zwiększenie frakcji udziału konwolucji $3\\times3$ i $5\\times5$ na wyższych poziomach\n",
    "  * a to staje się coraz bardziej kosztowne na wyższych poziomach\n",
    "  * łączenie wyjścia poolingu oraz konwolucji spowoduje zwiększenie liczby wyjść z każdym krokiem, co będzie nieefektywne\n",
    "5. rozwiązaniem może być __redukcja__ wymiarowości gdziekolwiek to możliwe\n",
    "  * wykorzystywane jest tu podejście embeddingu\n",
    "  * konwolucje $1\\times1$ są obliczane przed kosztownymi $3\\times3$ i $5\\times5$\n",
    "  * moduł Inception na rysunku po prawej\n",
    "6. moduły inception są ustawiane jeden po drugim\n",
    "  * to pozwala na zwiększanie ich liczby __bez__ niekontrolowanego wzrostu złożoności"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet\n",
    "\n",
    "<img src=\"nn_figures/googlenet.pdf\" width=\"100%\">\n",
    "1. sieć jest bardzo głęboka\n",
    "  * propagacja gradientów wgłąb może być problemem\n",
    "  * aby cały model dawał dobre wyniki, cechy generowane na niższych i środkowych warstwach powinny być dyskryminatywne\n",
    "2. GoogLeNet dodaje klasyfikatory na niższych i środkowych poziomach\n",
    "  * powinny wzmacniać poprawne klasyfikacje na tych poziomach\n",
    "  * zwiększać sygnał gradientu\n",
    "  * dodawać regularyzację\n",
    "3. te klasyfikatory\n",
    "  * są dodane w środkowych modułach 4a i 4d\n",
    "  * mają postać małych sieci konwolucyjnych\n",
    "  * ich koszt jest dodawany do całkowitego zdyskontowane (zwykle ich koszty przemnożone przez 0.3)\n",
    "  * usunięte w trakcie inferencji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liczba parametrów\n",
    "1. AlexNet miał ok. 60 milionów\n",
    "2. VGG19 osiągnął w ILSVR'2014 wynik minimalnie słabszy od GoogLeNet\n",
    "3. VGG19 ma zaletę bardzo __prostej__ architektury ale kosztem olbrzymiej liczby parametrów - ok. 180 milionów\n",
    "4. GoogLeNet ma tylko 5 milionów parametrów\n",
    "  * powinna być lepsza generalizacja\n",
    "  * mniej dodatkowych chwytów (augmentacja, itp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dekonwolucje\n",
    "1. dekonwolucje są w rzeczywistości transponowanymi konwolucjami\n",
    "2. pozwalają odwrócić cykl\n",
    "  * cześć konwolucyjna od obrazu do reprezentacji\n",
    "  * część odwracająca reprezentację do postaci obrazu\n",
    "  \n",
    "<img src=\"nn_figures/101-inp.jpg\" width=\"45%\"><img src=\"nn_figures/101-out.jpg\" width=\"45%\">\n",
    "<img src=\"nn_figures/699-inp.jpg\" width=\"45%\"><img src=\"nn_figures/699-out.jpg\" width=\"45%\"> [za P. Garg]\n",
    "  * konwolucyjna\n",
    "    * Conv2d(16, 4) -> ReLU -> MaxPool(2) -> Conv2d(32, 5) -> ReLU -> MaxPool(2) -> Conv2d(64, 3) -> ReLU\n",
    "  * dekonwolucyjna \n",
    "    * ConvTransp2d(32, 3) -> ReLU -> MaxUnPool(2) -> ConvTransp2d(16, 5) -> ReLU -> MaxUnPool(2) -> ConvTransp2d(3, 4) -> ReLU\n",
    "3. pozwala na odszumianie oraz semantyczną segmentację\n",
    "4. max-pool __nie jest__ operacją odwracalną\n",
    "  * jak zrobić un-pooling?\n",
    "    * zapamiętując indeksy\n",
    "      * każdy max-pool zapamietuje __która__ z pozycji w kernelu (np. 2x2) miała najwyższą wartość\n",
    "      * przy odwracaniu ta pozycja dostaje wartość wyjściową, a pozostałe 0\n",
    "    * a jeśli indeksy __nie są__ dostępne?\n",
    "      * niech architektura będzie architekturą autoenkodera\n",
    "      * od wejścia do warstwy latent $Z$ jest sieć konwolucyjna\n",
    "      * od latent do wyjściowej dekonwolucyjna\n",
    "      * zadaniem jest __wylosować__ $z\\in{}Z$ co nie podaje indeksów\n",
    "      * najprostszym rozwiązaniem jest __upsampling__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network in Network\n",
    "1. filtr konwolucji jest w rzeczywistości uogólnionym modelem liniowym (GLM)\n",
    "  * poziom abstrakcji nie jest wysoki\n",
    "  * konieczne jest tworzenie wielu filtrów\n",
    "  * problem gdy dane dla pewnego wzorca (concept) leżą na bardziej skomlikowanej powierzchni niż półpłaszczyna\n",
    "2. warstwa __mlpconv__ wykorzystuje nieliniowy detektor\n",
    "<img src=\"nn_figures/nin.pdf\" width=\"100%\">\n",
    "  * filtr konwolucyjny wraz z nieliniową aktywacją, np. ReLU, oblicza $$f_{ijk}\\max(w_K^Tx_{ij},0)$$\n",
    "    * naturalnie obliczana jest liczba warstw zgodna z definicją MLP - może być głęboką siecią\n",
    "  * podobnie mlpconv mapuje pewien obszar (patch) do wartości wyjsciowej w następnej warstwie\n",
    "  * dzieje się tak przez wielowarstwowy perceptron z nielioniowymi aktywacjami\n",
    "  * MLP jest __wspólny__ dla wszystkich lokalnych pól wejściowych\n",
    "  * średnia ostatniej warstwy jest przekazywana jako wartość zaufania do obliczonych cech\n",
    "  * to przypomina $maxout$ gdzie wybierane jest maksimum z wielu obliczonych wartości"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucje $1\\times1$\n",
    "1. nikt nam nie zabrania ustalenia wymiaru kernela na $k=1$, ale po co...?\n",
    "2. konwolucja $1\\times1$ oblicza __nieliniową__ funkcję na pojedynczej kolumnie pikseli obrazu\n",
    "  * to może być moduł typu NiN\n",
    "3. pozwala na efektywną redukcję wymiarowości, tzn. liczby kanałów\n",
    "  1. 256 kanałów -- konwolucje 1x1 --> 64 kanały -- konwolucje 4x4 --> 256 kanałów\n",
    "  2. 256 kanałów -- konwolucje 4x4 --> 256 kanałów\n",
    "  * które rozwiązanie jest szybsze???\n",
    "4. konwolucje przestrzenne na kanałach przetworzonych wcześniej przez $1\\times1$ odpowiadają konwolucją na przestrzeniach osadzonych (__embedding__)\n",
    "  * takie konwolucje są bardzo wydajne nie tracąc informacji\n",
    "  * przetwarzania na embeddingach są bardzo popularne np. w NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densenet\n",
    "<img src=\"nn_figures/denseblock.pdf\" width=\"80%\"> [Huang, Liu, Weinberger, Maaten]\n",
    "1. wyjście z każdej warstwy (lub ich grupy) jest podłączone do __wszystkich późniejszych__ warstw\n",
    "  * połączenie jako \n",
    "    * konkatenacja wszystkich poprzednich warstw\n",
    "    * batch normalization\n",
    "    * ReLU\n",
    "    * konwolucja $3\\times3$\n",
    "2. ponieważ konkatenacja nie byłaby możliwa przy zmianie rozmiarów map warstwy są poddawana poolingowi w warstwach dostosowujących\n",
    "  * batch normalization\n",
    "  * konwolucje $1\\times1$\n",
    "  * $2\\times2$ average pooling\n",
    "3. przed konwolucjami $3\\times3$ dodawane są konwolucje $1\\times1$ dla zmniejszenia wymiarowości i poprawie efektywności\n",
    "<img src=\"nn_figures/densenet.png\" width=\"100%\"> [Huang, Liu, Weinberger, Maaten]\n",
    "4. DenseNet z różnymi parametrami (wielkościami warstw, ich głębokościami, etc) osiągał (wg. metodologii takiej jak w AlexNet) na zbiorze ILSVRC'2012\n",
    "  * top-1: 23.6%, 22.1%, 21.5%, 20.8%\n",
    "  * top-5: 6.66%, 5.92%, 5.44%, 5.29%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeezenet\n",
    "<img src=\"nn_figures/squeezenet.png\" width=\"100%\"> [Indola, Han, Moskewicz, Ashraf, Dally, Keutzer]\n",
    "1. celem autorów było __zmniejszenie__ sieci CNN\n",
    "  * łatwiej jest uczyć małe modele w równoległym środowisku\n",
    "  * prostsza aktualizacja nauczonych modeli, np. automatyczna przez Internet\n",
    "  * możliwość implementacji na FPGA\n",
    "2. próba rozwiązania w Squeezenet wykorzystując\n",
    "  * zamiana dużej liczby konwolucji $3\\times3$ na konwolucje $1\\times1$\n",
    "  * zmniejszenie liczby kanałów wejściowych dla konwolucji $3\\times3$\n",
    "    * przez wykorzystanie warstw __squeeze__\n",
    "  * downsampling (pooling) __późno__ w architekturze, by konwolucje miały większe mapy aktywacji, co prowadzi do niższych błędów\n",
    "3. moduł __fire__\n",
    "<img src=\"nn_figures/squeezenet-fire.pdf\" width=\"60%\"> [Indola, Han, Moskewicz, Ashraf, Dally, Keutzer]\n",
    "  * moduł zgniatający z konwolucji $1\\times1$\n",
    "  * przekazujący wyjście do konwolucji $1\\times1$ i $3\\times3$\n",
    "  * pozwala na zmniejszenie liczby kanałów wejsciowych do konwolucji $3\\times3$\n",
    "4. końcowa warstwa __nie ma__ pełnych połączeń, a tylko _average pooling_ jak w NiN\n",
    "5. metoda kompresji sieci zastosowana do\n",
    "  * AlexNet\n",
    "    * SVD zmniejsza sieć 5-krotnie i top-1 do 56%\n",
    "    * Network Preuning 9-krotnie, top-1 do 57.2%, top-5 do 29.8%\n",
    "    * Deep Compression zmniejsza AlexNet 35-krotnie bez zmiany poziomu błędu\n",
    "  * SqueezeNet osiąga 50-krotną redukcję względem AlexNet __bez zmiany__ poziomów błędu\n",
    "    * Deep Compression z 6-bitową kwantyzacją i 33% rzadkością daje model o wielkości ok. 0.47MB\n",
    "      * ponad 500 razy mniejszy niż AlexNet!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
