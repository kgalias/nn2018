{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<big><big><big><big><big><big>Sieci neuronowe 2018</big></big></big></big></big></big>\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<big><big><big><big><big>Wstęp</big></big></big></big></big>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<id=tocheading><big><big><big><big>Spis treści</big></big></big></big>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set(font_scale=2.0)\n",
    "# from bokeh.io import gridplot, output_file, show\n",
    "#from bokeh.plotting import figure, output_notebook\n",
    "# from bkcharts import Scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Image inclusion\n",
    "<img src=\"../nn_figures/\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"nn_figures/sgd-various-speed.gif\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"nn_figures/learning_types.png\" width=\"100%\"> [https://www.pinterest.com/pin/274578908514098592/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Uczenie maszynowe\n",
    "1. __uczenie maszynowe__ tworzenie rozwiązań na podstawie zbioru przykładów\n",
    "2. __nadzorowane__\n",
    "  * ciągłe / kategoryczne zmienne zależne\n",
    "  * regresja klasyfikacja\n",
    "  * __skończony__ zbiór danych o postaci \n",
    "  * modele warstwowe, modele rekurencyjne\n",
    "3. __nie-nadzorowane__\n",
    "  * klastrowanie / asocjacja\n",
    "  * podział przestrzeni\n",
    "  * dane $\\{(x_i)\\}_{i=1}^N$\n",
    "4. __semi-nadzorowane__\n",
    "  * kategoryczne dane\n",
    "  * klasyfikacja / klastrowanie\n",
    "  * zbiór danych jako połączenie danych etykietowanych i nie etykietowanych\n",
    "  * próba rozwiazania dla problemu braku danych przy wysokim koszcie etykietowania \n",
    "5. __ze wzmocnieniem__ (reinforcement)\n",
    "  * klasyfikacja / sterowanie\n",
    "  * dane nie posiadają __prawidłowych__ odpowiedzi\n",
    "  * tzw. __środowisko__ ocenia prawidłowość wykonanych akcji\n",
    "    * ocena może nastąpić po jednej albo wielu akcjach\n",
    "    * stąd tzw. _temporal credit_ problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci neuronowe\n",
    "1. Biologiczne analogie\n",
    "<img src=\"nn_figures/neuron.png\" width=\"100%\">[https://en.wikipedia.org/wiki/Neuron]\n",
    "  * ciało komórki\n",
    "  * dendryty i aksony\n",
    "  * strefa spustowa\n",
    "  * potencjał synaptyczny\n",
    "  <img src=\"nn_figures/potential.gif\" width=\"100%\">\n",
    "  * synapsa i neuroprzekaźniki\n",
    "  <img src=\"nn_figures/synapse.jpg\" width=\"100%\">[http://learn.genetics.utah.edu/content/neuroscience/neurons/]\n",
    "  * budowa całego systemu nerwowego jest bardzo złożona\n",
    "2. neuron biologiczny jest wysoce nieliniowy\n",
    "  * ciało komórki musi osiągnąć wystarczający potencjał by zainicjować (ang. fire) sygnał wzdłuż aksonu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Różne rodzaje sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Modele liniowe__\n",
    "<img src=\"nn_figures/linear.png\" width=\"70%\">\n",
    "\n",
    "$$Y=\\theta^TX$$\n",
    "  2. X może być przedstawione przez __funkcje bazowe__\n",
    "    * np. wielomiany, f. Fouriera, wavelet, etc.\n",
    "    * funkcje bazowe muszą być definiowane _a priori_\n",
    "  3. rozwiązanie __dla problemu regresji__ będzie polegać na minimalizacji __kwadratowej funkcji kosztu__\n",
    "  $$L(\\theta)=\\sum_k(y_k-\\widehat{y}_k)^2,$$\n",
    "  gdzie $\\widehat{y}$ jest wynikiem działania modelu\n",
    "    * kwadratowa fuknkcja kosztu wynika z założenia o normalności błędów \n",
    "    $$y_i=F(x_i)+\\epsilon$$\n",
    "    gdzie $F$ nieznaną funkcją, a $\\epsilon$ to błąd i $\\epsilon\\sim\\mathcal{N}(0,\\sigma)$\n",
    "    * przykładowo: \n",
    "      1. fabryka produkuje patyki opisane przez parametry $x_i$\n",
    "      2. mają długości $y_i$ zmierzone za pomocą pewnej miarki\n",
    "        * a więc obciążone __nieusuwalnym__ błędem\n",
    "        * zakładamy, że ten błąd ma rozkład normalny\n",
    "      3. zadanie polega na przewidzeniu długości\n",
    "  4. zwykle __rozszerzony__ wektor wejsciowy $x=[1, x]$ co wprowadza przesunięcie\n",
    "  $$\\theta^Tx=\\theta^t[1,x_1,\\dots,x_K]=\\theta_0+\\theta_1x_1+\\dots+\\theta_Dx_D$$\n",
    "    * bez rozszerzenia hiperpłaszczyzna przechodzi przez początek układu współrzędnych\n",
    "  5. model liniowy ma jedno minimum -- funkcja kosztu jest wypukła\n",
    "    * można rozwiązać z pomocą\n",
    "    $$\\widehat{\\theta}=(X^TX)^{-1}X^Ty$$ \n",
    "    pod warunkiem istnienia $(X^TX)^{-1}$\n",
    "      * zwraca wynik dokładny, jednak odwracanie $(X^TX)^{-1}$ jest złożone obliczeniowo i źle uwarunkowane\n",
    "      * $X^TX$ m wymiar $D\\times{}D$\n",
    "    * uczenie za pomocą SGD\n",
    "  6. modele liniowe mają ograniczone zastosowanie, ale są czytelne"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele warstwowe\n",
    "1. <img src=\"nn_figures/perceptron.jpg\" width=\"100%\">[https://towardsdatascience.com]\n",
    "  * tzw. McCulloch-Pitts model, także Rosenblatta\n",
    "  * wprowadzona twarda nieliniowość\n",
    "2. algorytm uczenia\n",
    "```\n",
    "while not wszystkie przykłady poprawnie klsyfikowane:\n",
    "   (x, y) = kolejny przykład\n",
    "   if y != net(x):\n",
    "      # przykład źle klasyfikowany\n",
    "      w = w + eta * (y - net(x)) * x\n",
    "```\n",
    "  * jeśli przykłady są separowalne liniowo, to algorytm na pewno zakończy się dla $\\eta > 0$\n",
    "  * to algorytm przez poprawianie błędów\n",
    "  * to algorytm przez spadek gradientu\n",
    "3. wiele problemów __nie jest__ liniowo separowalnych\n",
    "  * nawet jeśli są __tylko trochę__ nieseparowalne, to algorytm może doprowadzić do bzdurnych rozwiązań\n",
    "    * są pewne modyfikacje, tzw. algorytm __pocket__\n",
    "4. potrzebne rozwinięcie architektury - sieci __wielowarstwowe__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele wielowarstwowe\n",
    "<img src=\"nn_figures/multilayer.png\" width=\"100%\">[https://www.researchgate.net]\n",
    "1. jedna lub więcej warstw __ukrytych__ (hidden, latent)\n",
    "2. warstwy ukryte wykorzystują __nieliniowe__ funkcje aktywacji\n",
    "  * sigmoidalne, ReLU, RBF, i wiele pochodnych\n",
    "  * użycie aktywacji liniowej __redukuje__ model do liniowej bez warstw ukrytych\n",
    "3. uczenie\n",
    "  * analogicznie do sieci bez warstw uktytych?\n",
    "    1. oblicz błąd $(y-\\widehat{y})$\n",
    "    2. zaaplikuj poprawkę $ w=w+\\eta(y-\\widehat{y})x$\n",
    "  * jaki jest błąd dla neuronów w warstwach ukrytych?\n",
    "    * a raczej jaka jest poprawna aktywacja???\n",
    "4. dopiero algorytm wstecznej propagacji...\n",
    "5. problem klasyfikacji\n",
    "  * podstawowe modele są __binarne__\n",
    "  * __wieloklasowe__ (multiclass) $$y\\in\\{c_1,\\dots,c_K\\}$$\n",
    "    * zwykle reprezentacja __one_hot__\n",
    "    * może odpowiadać $K$ klasyfikatorom binarnym o wspólnych warstwach\n",
    "    * wyjście można próbować zinterpretować jako __prawdopodobieństwo__ klas $P(c_i\\mid x)$\n",
    "      * przez funkcję __softmax__\n",
    "      $$\\widehat{y}_i=\\frac{\\exp(y_i)}{\\sum_l\\exp(y_l)}$$\n",
    "  * __wieloetykietowe__ (multilabel)\n",
    "    * \"prawdziwa\" może być więcej niż jedna klasa wyjściowa\n",
    "    * może odpowiadać problemowi klasyfikacji wielopoziomowej\n",
    "    * trudny problem: zależności miedzy klasami, trudna deifinicja funkcji kosztu, wartość wyjść nie sumuje się do jedności, ani do ustalonej wartości"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inne modele\n",
    "<img src=\"nn_figures/neuralnetworks.png\" width=\"100%\">[asimovinstitute.org]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metody uczenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pakiety\n",
    "(w żadnym wyróżnionym porządku niewyczerpująca lista)\n",
    "1. __numpy__, __scipy__\n",
    "  * wysoko wydajna biblioteka matematyczna\n",
    "  * wektoryzacja obliczeń\n",
    "  * obliczenia statystyczne w scipy\n",
    "1. __scikit-learn__ http://scikit-learn.org/stable/\n",
    "  * głównie metody bardziej klasycznego uczenia maszynowego\n",
    "  * wiele metod preprocessingu, redukcji wymiarowości, wyboru modelu,  wizualizacji\n",
    "  * sieci neuronowe wyłącznie dla zastosowań w małej skali\n",
    "2. __Theano__ https://github.com/Theano/Theano\n",
    "  * środowisko definiujące model obliczeniowy jako optymalizowany graf\n",
    "  * węzły obliczeniowe jako tensory\n",
    "  * MILA przerywa rozwijanie środowiska\n",
    "  * to samo wcześniej spotkało Pylearn2\n",
    "    * okropnie nieczytelny poprzez poprawnego programowania (moim zdaniem)\n",
    "  * trudny w zrozumieniu: algorytm zrozumienia\n",
    "    1. rozpocznij czytanie instrukcji obsługi Theano\n",
    "    2. gdy zorientujesz się, że programowanie w czystym Theano jest wyjatkowo złożone, znajdź bibliotekę używajacą Theano\n",
    "    3. używaj jej od tego momentu\n",
    "  * __Lasagne__ https://github.com/Lasagne/Lasagne ułatwia programowanie NN w Theano\n",
    "3. __Tensorflow__ https://www.tensorflow.org\n",
    "  * opracowywane przez Google Brain\n",
    "  * graf obliczeniowy z operacjami definiowanymi jako tensory\n",
    "  * ma złożoną architekturę:\n",
    "    * system wykonawczy na CPU, GPU, IoS, Android, etc.\n",
    "    * interface w C++, Pythonie\n",
    "  * wbudowana obsługa wielu GPU\n",
    "  * szybko rozwijany (spory zespół)\n",
    "  * dokumentacja w miarę czytelna\n",
    "  * ma bardzo fajny dodatek Tensorboard do śledzenia postępów uczenia\n",
    "  * duży zespół prowadzi szeroki rozwój, np. badając ograniczenie pamięci na aktywacje\n",
    "  * dobry system gdy tworzymy modele produkcyjne\n",
    "4. __Keras__ The Python Deep Learning Library https://keras.io\n",
    "  * \"Keras (κέρας) means horn in Greek. It is a reference to a literary image from ancient Greek and Latin literature, first found in the Odyssey, where dream spirits (Oneiroi, singular Oneiros) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. It's a play on the words κέρας (horn) / κραίνω (fulfill), and ἐλέφας (ivory) / ἐλεφαίρομαι (deceive).\"\n",
    "  * obsługuje Theano, Tensorflow a także CNTK (Microsoft Cognitive Toolkit) jako backendy\n",
    "  * działa na CPU / GPU bez różnicy\n",
    "  * nie wymaga dodatkowej wiedzy i rozumienia grafów obliczeniowych, a wszystko jest napisane jak Python\n",
    "  * prosta konstrukcja stosunkowo złożonych architektur\n",
    "  * od wersji 2.0 umozliwia wygodny zapis _funkcjonalny_ (obecnie wersja 2.0.8)\n",
    "  ```\n",
    "  x = Dense(128)(inputs)   \n",
    "  x = Dense(64)(x)\n",
    "  ```\n",
    "  * ma czasem błędy, które pojawiają się całkiem niespodziwanie\n",
    "  * czasem zupełnie bez wcześniejszego ostrzeżenia znikają niektóre architektury\n",
    "    * np. auto-enkoder czy Highway (jest w osobnej bibliotece)\n",
    "  * jest fajny blog https://blog.keras.io\n",
    "  * całkiem dobra instrukcja obsługi wraz z przykładami\n",
    "  * twórca Francois Chollet jest teraz w Google, więc jak długo bedzie Keras działał?\n",
    "    * prawdopodobnie Keras stanie się jeszcze bardziej wysokopoziomowym interfacem do Tensorflow\n",
    "    * Chollet bardzo aktywny na Twitterze\n",
    "5. __Torch__ http://torch.ch\n",
    "  * napisany dla Lua pakiet przypominający numpy w użyciu (a numpy przypomina MATLAB)\n",
    "  * PyTorch dla Pythona\n",
    "  * w Torchu (w odróżnieniu od np. Tensorflow) graf jest definiowany dynamicznie, nie statycznie\n",
    "    * różniczkowanie z wykorzystaniem Autograd\n",
    "  * debugging w miarę prosty (nie jak w Tensorflow)\n",
    "  * http://pytorch.org dla Pythona\n",
    "    * \"A replacement for NumPy to use the power of GPUs\"\n",
    "6. __Caffe__ http://caffe.berkeleyvision.org\n",
    "  * utworzony w Berkeley AI Research\n",
    "  * dużo aplikacji rozpoznawania obrazów\n",
    "  * nie ma automatycznego różniczkowania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sequence\n",
    "Alice->Bob: Hello Bob, how are you?\n",
    "Note right of Bob: Bob thinks\n",
    "Bob-->Alice: I am good thanks!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
