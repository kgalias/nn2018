{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network - part B\n",
    "\n",
    "In this notebook we will look a very quickl look at what convolutional layers learn\n",
    "\n",
    "Goal of this lab is to:\n",
    "\n",
    "* Visualize and understand what convolutional layer learns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional project - reproducibility challenge\n",
    "\n",
    "You are welcome to work on it during the lab if you have finished the exercises. https://www.cs.mcgill.ca/~jpineau/ICLR2018-ReproducibilityChallenge.html\n",
    "\n",
    "* Counts as 4 points (~ should be approximately worth of exercises from 2 labs)\n",
    "* Pick an ICLR paper and then consult the choice\n",
    "* Deadline for submitting the report is 20.06.2018, 23:59:59.\n",
    "* Don't pick papers submitted by GMUM :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whiteboard exercises\n",
    "\n",
    "( + Any exercise from the previous labs )\n",
    "\n",
    "* (0.5) What is the most common way to apply batch normalization to convolutional layer output? Provide an explanation behind it. Reference: https://arxiv.org/pdf/1502.03167v3.pdf.\n",
    "\n",
    "* (0.5) Look up instance normalization, a variant of batch normalization. Explain: (i) how it works, (ii) when and why it might be preferable to batch normalization.\n",
    "\n",
    "* (0.5) Should we apply batch normalization before or after Dense layer? Provide an explanation. Reference: https://arxiv.org/pdf/1502.03167v3.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Boilerplate code to get started\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "from src import fmnist_utils\n",
    "from src.fmnist_utils import *\n",
    "\n",
    "from torchvision import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(H):\n",
    "    plt.title(max(H['test_acc']))\n",
    "    plt.plot(H['acc'], label=\"acc\")\n",
    "    plt.plot(H['test_acc'], label=\"test_acc\")\n",
    "    plt.legend()\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['figure.figsize'] = (7, 7)\n",
    "mpl.rcParams['axes.titlesize'] = 12\n",
    "mpl.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fmnist_utils.get_data(which=\"mnist\")\n",
    "\n",
    "x_train_4d = x_train.view(-1, 1, 28, 28)\n",
    "x_test_4d = x_test.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Convolution vs FC on FMNIST\n",
    "\n",
    "* Fill out blanks in the code\n",
    "* Train an MLP and a ConvNet for the supplied hyperparameters. Which one works better in terms of generalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_conv(input_dim, output_dim, n_filters=32, maxpool=4, hidden_dims=[32], dropout=0.0):\n",
    "    model = torch.nn.Sequential()\n",
    "    \n",
    "    # Convolution part\n",
    "    model.add_module(\"conv2d\", torch.nn.Conv2d(input_dim[0], n_filters, kernel_size=5, padding=??))\n",
    "    model.add_module(\"relu\", torch.nn.ReLU()) \n",
    "    model.add_module(\"maxpool\", torch.nn.MaxPool2d(maxpool))\n",
    "    model.add_module(\"dropout\", torch.nn.Dropout2d(dropout))\n",
    "    model.add_module(\"flatten\", ??) # Add flattening from 4d -> 2d. \n",
    "    \n",
    "    previous_dim = ??\n",
    "    \n",
    "    # Classifier\n",
    "    for id, D in enumerate(hidden_dims):\n",
    "        model.add_module(\"linear_{}\".format(id), torch.nn.Linear(previous_dim, D, bias=True))\n",
    "        model.add_module(\"nonlinearity_{}\".format(id), torch.nn.ReLU())\n",
    "        previous_dim = D\n",
    "    model.add_module(\"final_layer\", torch.nn.Linear(D, output_dim, bias=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Starting code for training a ConvNet.\n",
    "input_dim = (1, 28, 28)\n",
    "\n",
    "model = build_conv(input_dim, 10, n_filters=32, dropout=0.5)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss(size_average=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "H = train(loss=loss, model=model, x_train=x_train_4d, y_train=y_train,\n",
    "          x_test=x_test_4d, y_test=y_test,\n",
    "          optim=optimizer, batch_size=128, n_epochs=50)\n",
    "\n",
    "plot(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Starting code for training a MLP.\n",
    "\n",
    "model = build_mlp(784, 10)\n",
    "loss = torch.nn.CrossEntropyLoss(size_average=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "H_mlp = train(loss=loss, model=model, x_train=x_train, y_train=y_train,\n",
    "          x_test=x_test, y_test=y_test, optim=optimizer, batch_size=128, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: examine filters\n",
    "\n",
    "1. Plot filters from *best validation epoch* of the model in exercise 1. Please save them to file \"9b_1.png\".\n",
    "\n",
    "2. Plot filter from different epochs. How are they changing? In which epochs do the filters stabilize? Please save your answer to \"9b_2.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Starting code for Ex2.1\n",
    "\n",
    "def vistensor(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
    "    '''\n",
    "    vistensor: visuzlization tensor\n",
    "        @ch: visualization channel \n",
    "        @allkernels: visualization all tensores\n",
    "    ''' \n",
    "    \n",
    "    n,c,w,h = tensor.shape\n",
    "    if allkernels: tensor = tensor.view(n*c,-1,w,h )\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "        \n",
    "    rows = np.min( (tensor.shape[0]//nrow + 1, 64 )  )    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "filters = ?? # Get Torch Tensor corresponding to filters from the best validation point in training\n",
    "vistensor(filters, ch=0, allkernels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
