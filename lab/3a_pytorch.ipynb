{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mulitnomial Logistic Regression in PyTorch\n",
    "\n",
    "Your task will be to:\n",
    "\n",
    "* Implement and optimize multinomial logistic regression using Pytorch using Autograd\n",
    "\n",
    "Goal is to:\n",
    "\n",
    "* Understand and learn basics of PyTorch\n",
    "* Revise multinomial logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kg/miniconda3/envs/nn2018/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['figure.figsize'] = (7, 7)\n",
    "mpl.rcParams['axes.titlesize'] = 12\n",
    "mpl.rcParams['axes.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get FashionMNIST (see 1b_FMNIST.ipynb for data exploration)\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Logistic regression needs 2D data\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# 0-1 normalization\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# For simplicity - implicit bias\n",
    "x_train = np.concatenate([np.ones_like(x_train[:, 0:1]), x_train], axis=1)\n",
    "x_test = np.concatenate([np.ones_like(x_test[:, 0:1]), x_test], axis=1)\n",
    "\n",
    "# Convert to Torch Tensor. Just to avoid boilerplate code later\n",
    "x_train = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "# Use only first 1k examples. Just for notebook to run faster\n",
    "x_train, y_train = x_train[0:1000], y_train[0:1000]\n",
    "x_test, y_test = x_test[0:1000], y_test[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why not Numpy\n",
    "\n",
    "Ref: http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture8.pdf\n",
    "\n",
    "<img src=\"https://github.com/gmum/nn2018/raw/master/lab/fig/2/GPUvsCPU.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch mini tutorial\n",
    "\n",
    "Ref: http://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n",
    "\n",
    "PyTorch has 3 layers of abstraction\n",
    "\n",
    "<img width=300 src=\"https://github.com/gmum/nn2018/raw/master/lab/fig/3/cake.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First layer: torch Tensor\n",
    "\n",
    "First layer is basically numpy, but with ability to execute on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 12 20]\n"
     ]
    }
   ],
   "source": [
    "a = torch.IntTensor([2, 3, 4])\n",
    "b = torch.IntTensor([3, 4, 5])\n",
    "m = a * b  # element-wise product\n",
    "print(m.numpy())  # convert to the numpy array [ 6 12 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.4991  0.8046  0.6383\n",
      " 0.5512  0.0703  0.2927\n",
      " 0.0378  0.4827  0.2848\n",
      " 0.1036  0.7897  0.3666\n",
      " 0.1148  0.0287  0.5326\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.1035  0.9545  1.4725\n",
      " 1.1324  0.4428  0.2963\n",
      " 0.8617  0.9599  0.8716\n",
      " 0.5866  0.8803  1.3566\n",
      " 0.9298  0.0560  1.4999\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.1035  0.9545  1.4725\n",
      " 1.1324  0.4428  0.2963\n",
      " 0.8617  0.9599  0.8716\n",
      " 0.5866  0.8803  1.3566\n",
      " 0.9298  0.0560  1.4999\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.8046\n",
      " 0.0703\n",
      " 0.4827\n",
      " 0.7897\n",
      " 0.0287\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Just like numpy! Amazing!\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU execution by modifying flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y\n",
    "else:\n",
    "    print(\"No GPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second layer: Variable, computation graph and autograd\n",
    "\n",
    "torch.autograd.Variable uses internally torch.Tensor as .data field.\n",
    "\n",
    "When computing using wrapped in torch.Variable tensors, PyTorch creates computational graph for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /home/kg/miniconda3/envs/nn2018/lib/python3.6/site-packages\n",
      "Collecting git+https://github.com/szagoruyko/pytorchviz\n",
      "  Cloning https://github.com/szagoruyko/pytorchviz to /tmp/pip-loo7ejg6-build\n",
      "  Requirement already satisfied (use --upgrade to upgrade): pytorchviz==0.0.1 from git+https://github.com/szagoruyko/pytorchviz in /home/kg/miniconda3/envs/nn2018/lib/python3.6/site-packages\n",
      "Requirement already satisfied: torch in /home/kg/miniconda3/envs/nn2018/lib/python3.6/site-packages (from pytorchviz==0.0.1)\n",
      "Requirement already satisfied: graphviz in /home/kg/miniconda3/envs/nn2018/lib/python3.6/site-packages (from pytorchviz==0.0.1)\n",
      "Requirement already satisfied: pyyaml in /home/kg/miniconda3/envs/nn2018/lib/python3.6/site-packages (from torch->pytorchviz==0.0.1)\n",
      "Requirement already satisfied: numpy in /home/kg/miniconda3/envs/nn2018/lib/python3.6/site-packages (from torch->pytorchviz==0.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Get torchviz (might not work on some systems)\n",
    "!pip install graphviz\n",
    "!pip install git+https://github.com/szagoruyko/pytorchviz\n",
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "x = Variable(torch.ones(2, 4), requires_grad=True)\n",
    "y = w.mm(x) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"157pt\"\n",
       " viewBox=\"0.00 0.00 134.00 157.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 153)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-153 130,-153 130,4 -4,4\"/>\n",
       "<!-- 139676250056408 -->\n",
       "<g id=\"node1\" class=\"node\"><title>139676250056408</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"109,-21 17,-21 17,-0 109,-0 109,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 139676250056800 -->\n",
       "<g id=\"node2\" class=\"node\"><title>139676250056800</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"105.5,-78 20.5,-78 20.5,-57 105.5,-57 105.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139676250056800&#45;&gt;139676250056408 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>139676250056800&#45;&gt;139676250056408</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-56.9197C63,-49.9083 63,-40.1442 63,-31.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5001,-31.3408 63,-21.3408 59.5001,-31.3409 66.5001,-31.3408\"/>\n",
       "</g>\n",
       "<!-- 139676250057136 -->\n",
       "<g id=\"node3\" class=\"node\"><title>139676250057136</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-149 0,-149 0,-114 54,-114 54,-149\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (2, 2)</text>\n",
       "</g>\n",
       "<!-- 139676250057136&#45;&gt;139676250056800 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>139676250057136&#45;&gt;139676250056800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M36.6473,-113.885C41.4897,-105.545 47.3684,-95.4212 52.3436,-86.8527\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"55.4789,-88.4232 57.4736,-78.0178 49.4254,-84.9082 55.4789,-88.4232\"/>\n",
       "</g>\n",
       "<!-- 139676250055736 -->\n",
       "<g id=\"node4\" class=\"node\"><title>139676250055736</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"126,-149 72,-149 72,-114 126,-114 126,-149\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (2, 4)</text>\n",
       "</g>\n",
       "<!-- 139676250055736&#45;&gt;139676250056800 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>139676250055736&#45;&gt;139676250056800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M89.3527,-113.885C84.5103,-105.545 78.6316,-95.4212 73.6564,-86.8527\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"76.5746,-84.9082 68.5264,-78.0178 70.5211,-88.4232 76.5746,-84.9082\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f08e944aac8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "torch.Autograd works on torch.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)\n",
    "out.backward()\n",
    "print(x.grad) # dout/dx :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "x = Variable(torch.ones(2, 4), requires_grad=False)\n",
    "y = (w.mm(x) + 2).mean()\n",
    "grad,  = torch.autograd.grad(y, w, create_graph=True, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"106pt\" height=\"213pt\"\n",
       " viewBox=\"0.00 0.00 106.00 213.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 209)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-209 102,-209 102,4 -4,4\"/>\n",
       "<!-- 139676250057248 -->\n",
       "<g id=\"node1\" class=\"node\"><title>139676250057248</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"98,-21 0,-21 0,-0 98,-0 98,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">MeanBackward1</text>\n",
       "</g>\n",
       "<!-- 139676250056632 -->\n",
       "<g id=\"node2\" class=\"node\"><title>139676250056632</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-78 3,-78 3,-57 95,-57 95,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 139676250056632&#45;&gt;139676250057248 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>139676250056632&#45;&gt;139676250057248</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49,-56.9197C49,-49.9083 49,-40.1442 49,-31.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.5001,-31.3408 49,-21.3408 45.5001,-31.3409 52.5001,-31.3408\"/>\n",
       "</g>\n",
       "<!-- 139676250058088 -->\n",
       "<g id=\"node3\" class=\"node\"><title>139676250058088</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"91.5,-135 6.5,-135 6.5,-114 91.5,-114 91.5,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139676250058088&#45;&gt;139676250056632 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>139676250058088&#45;&gt;139676250056632</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49,-113.92C49,-106.908 49,-97.1442 49,-88.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.5001,-88.3408 49,-78.3408 45.5001,-88.3409 52.5001,-88.3408\"/>\n",
       "</g>\n",
       "<!-- 139676250057864 -->\n",
       "<g id=\"node4\" class=\"node\"><title>139676250057864</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"76,-205 22,-205 22,-171 76,-171 76,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">w</text>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (2, 2)</text>\n",
       "</g>\n",
       "<!-- 139676250057864&#45;&gt;139676250058088 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>139676250057864&#45;&gt;139676250058088</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49,-170.842C49,-163.012 49,-153.54 49,-145.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.5001,-145.042 49,-135.042 45.5001,-145.042 52.5001,-145.042\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f08e944a940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(y, params={\"w\": w})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"76pt\" height=\"29pt\"\n",
       " viewBox=\"0.00 0.00 76.00 29.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 25)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-25 72,-25 72,4 -4,4\"/>\n",
       "<!-- 139678202850640 -->\n",
       "<g id=\"node1\" class=\"node\"><title>139678202850640</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"68,-21 0,-21 0,-0 68,-0 68,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">NoneType</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f08e944ae10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(grad, params={\"w\": w, \"x\": x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third layer: torch.nn\n",
    "\n",
    "Not much about it now. We will work much closer with later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('W0', nn.Linear(8, 16))\n",
    "model.add_module('tanh', nn.Tanh())\n",
    "model.add_module('W1', nn.Linear(16, 1))\n",
    "\n",
    "x = Variable(torch.randn(1,8))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"316pt\" height=\"340pt\"\n",
       " viewBox=\"0.00 0.00 315.50 340.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 336)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-336 311.5,-336 311.5,4 -4,4\"/>\n",
       "<!-- 139676241134312 -->\n",
       "<g id=\"node1\" class=\"node\"><title>139676241134312</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"217,-21 119,-21 119,-0 217,-0 217,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">MeanBackward1</text>\n",
       "</g>\n",
       "<!-- 139676241134200 -->\n",
       "<g id=\"node2\" class=\"node\"><title>139676241134200</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"220,-78 116,-78 116,-57 220,-57 220,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 139676241134200&#45;&gt;139676241134312 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>139676241134200&#45;&gt;139676241134312</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168,-56.9197C168,-49.9083 168,-40.1442 168,-31.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.5,-31.3408 168,-21.3408 164.5,-31.3409 171.5,-31.3408\"/>\n",
       "</g>\n",
       "<!-- 139676241133752 -->\n",
       "<g id=\"node3\" class=\"node\"><title>139676241133752</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"102,-135 7.10543e-15,-135 7.10543e-15,-114 102,-114 102,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"51\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 139676241133752&#45;&gt;139676241134200 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>139676241133752&#45;&gt;139676241134200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71.3798,-113.92C89.8888,-105.219 117.415,-92.2792 138.358,-82.4343\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"139.9,-85.5768 147.461,-78.155 136.922,-79.2418 139.9,-85.5768\"/>\n",
       "</g>\n",
       "<!-- 139676241134648 -->\n",
       "<g id=\"node4\" class=\"node\"><title>139676241134648</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"79,-205 23,-205 23,-171 79,-171 79,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"51\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">W1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"51\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 139676241134648&#45;&gt;139676241133752 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>139676241134648&#45;&gt;139676241133752</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51,-170.842C51,-163.012 51,-153.54 51,-145.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.5001,-145.042 51,-135.042 47.5001,-145.042 54.5001,-145.042\"/>\n",
       "</g>\n",
       "<!-- 139676241134928 -->\n",
       "<g id=\"node5\" class=\"node\"><title>139676241134928</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"216,-135 120,-135 120,-114 216,-114 216,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">TanhBackward0</text>\n",
       "</g>\n",
       "<!-- 139676241134928&#45;&gt;139676241134200 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>139676241134928&#45;&gt;139676241134200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168,-113.92C168,-106.908 168,-97.1442 168,-88.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.5,-88.3408 168,-78.3408 164.5,-88.3409 171.5,-88.3408\"/>\n",
       "</g>\n",
       "<!-- 139676241135096 -->\n",
       "<g id=\"node6\" class=\"node\"><title>139676241135096</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"219,-198.5 115,-198.5 115,-177.5 219,-177.5 219,-198.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"167\" y=\"-184.9\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 139676241135096&#45;&gt;139676241134928 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>139676241135096&#45;&gt;139676241134928</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.156,-177.391C167.295,-168.866 167.502,-156.139 167.676,-145.423\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.178,-145.3 167.842,-135.245 164.179,-145.187 171.178,-145.3\"/>\n",
       "</g>\n",
       "<!-- 139676241134368 -->\n",
       "<g id=\"node7\" class=\"node\"><title>139676241134368</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"165,-262 63,-262 63,-241 165,-241 165,-262\"/>\n",
       "<text text-anchor=\"middle\" x=\"114\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 139676241134368&#45;&gt;139676241135096 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>139676241134368&#45;&gt;139676241135096</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.281,-240.891C130.169,-231.738 142.231,-217.741 151.841,-206.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.725,-208.605 158.602,-198.745 149.422,-204.035 154.725,-208.605\"/>\n",
       "</g>\n",
       "<!-- 139676241134480 -->\n",
       "<g id=\"node8\" class=\"node\"><title>139676241134480</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"142,-332 86,-332 86,-298 142,-298 142,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"114\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\">W0.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"114\" y=\"-305.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (16)</text>\n",
       "</g>\n",
       "<!-- 139676241134480&#45;&gt;139676241134368 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>139676241134480&#45;&gt;139676241134368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M114,-297.842C114,-290.012 114,-280.54 114,-272.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.5,-272.042 114,-262.042 110.5,-272.042 117.5,-272.042\"/>\n",
       "</g>\n",
       "<!-- 139676241134424 -->\n",
       "<g id=\"node9\" class=\"node\"><title>139676241134424</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"256.5,-262 183.5,-262 183.5,-241 256.5,-241 256.5,-262\"/>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139676241134424&#45;&gt;139676241135096 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>139676241134424&#45;&gt;139676241135096</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M211.719,-240.891C203.831,-231.738 191.769,-217.741 182.159,-206.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"184.578,-204.035 175.398,-198.745 179.275,-208.605 184.578,-204.035\"/>\n",
       "</g>\n",
       "<!-- 139676241135152 -->\n",
       "<g id=\"node10\" class=\"node\"><title>139676241135152</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"254.5,-332 185.5,-332 185.5,-298 254.5,-298 254.5,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\">W0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-305.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (16, 8)</text>\n",
       "</g>\n",
       "<!-- 139676241135152&#45;&gt;139676241134424 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>139676241135152&#45;&gt;139676241134424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220,-297.842C220,-290.012 220,-280.54 220,-272.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.5,-272.042 220,-262.042 216.5,-272.042 223.5,-272.042\"/>\n",
       "</g>\n",
       "<!-- 139676241134704 -->\n",
       "<g id=\"node11\" class=\"node\"><title>139676241134704</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"307.5,-135 234.5,-135 234.5,-114 307.5,-114 307.5,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139676241134704&#45;&gt;139676241134200 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>139676241134704&#45;&gt;139676241134200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M253.059,-113.92C237.058,-105.376 213.403,-92.7441 195.097,-82.9694\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.551,-79.778 186.081,-78.155 193.254,-85.9528 196.551,-79.778\"/>\n",
       "</g>\n",
       "<!-- 139676241134984 -->\n",
       "<g id=\"node12\" class=\"node\"><title>139676241134984</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"306.5,-205 237.5,-205 237.5,-171 306.5,-171 306.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"272\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">W1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"272\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1, 16)</text>\n",
       "</g>\n",
       "<!-- 139676241134984&#45;&gt;139676241134704 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>139676241134984&#45;&gt;139676241134704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271.737,-170.842C271.61,-163.012 271.456,-153.54 271.322,-145.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.817,-144.984 271.155,-135.042 267.818,-145.098 274.817,-144.984\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f08e8bc84e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(y.mean(), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial logistic regression\n",
    "\n",
    "(Using PyTorch)\n",
    "\n",
    "## Useful equations\n",
    "\n",
    "Let $D$ denote input dimension, $K$ denote number of classes. Class probabilities are given by the softmax distribution:\n",
    "\n",
    "<br>\n",
    "<font size=4>\n",
    "$ p(\\textbf{y} = k | \\textbf{x}, \\textbf{w}) = \\frac{\\exp(\\langle\\textbf{w}_k, \\textbf{x}\\rangle)}{\\sum_i^{K} \\exp(\\langle\\textbf{w}_i, \\textbf{x}\\rangle)}$\n",
    "</font>\n",
    "\n",
    ", where $w \\in \\mathbb{R}^{(D,K)}$, $w_k$ denotes $k^{th}$ row of the $w$ matrix. For $K=2$ equivalent to the binomial logistic regression discussed in the previous notebook:\n",
    "\n",
    "<br>\n",
    "<font size=4>\n",
    "$ p(\\textbf{y} | \\textbf{x}, \\textbf{w}) = \\sigma(\\langle\\textbf{w}, \\textbf{x}\\rangle)$\n",
    "</font>\n",
    "\n",
    "Same as in binary case, loss is the cross-entropy loss:\n",
    "\n",
    "<br>\n",
    "<font size=4>\n",
    "$ L(\\textbf{w}) = - \\sum_i y_i \\log(p(\\textbf{y_i} | \\textbf{x_i}, \\textbf{w}))$\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement helper functions \n",
    "\n",
    "Hint: very similar to 2a_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_pred, y):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred: torch.Variable, shape: (batch_size, K)\n",
    "        Probabiities\n",
    "    y: torch.Variable, shape: (batch_size,)\n",
    "        Correct classes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    loss: torch.Variable, shape: (1, )\n",
    "        Cross entropy loss\n",
    "    \"\"\"\n",
    "    # Hint: use y as indexes to retrieve appropriate columns of y_pred\n",
    "    return - y_pred[range(len(y.data)), y].log().mean()\n",
    "\n",
    "\n",
    "def softmax(h):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    h: torch.Variable, shape: (batch_size, K)\n",
    "        Logits\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y_pred: torch.Variable, shape: (batch_size, K)\n",
    "        Softmax on h\n",
    "    \"\"\"\n",
    "    return h.exp() / h.exp().sum(dim=1, keepdim=True)\n",
    "\n",
    "def forward(x, w):\n",
    "    return softmax(x.mm(w))\n",
    "\n",
    "def evaluate(w):\n",
    "    x = Variable(x_test)\n",
    "    y_test_pred = forward(x, w).data.numpy()\n",
    "    return np.mean(y_test_pred.argmax(axis=1) == y_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kg/miniconda3/envs/nn2018/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Asserts to help you implement the functions.\n",
    "D = 785\n",
    "K = 10\n",
    "\n",
    "x = Variable(x_train[0:100], requires_grad=False) # No grad wrt to data\n",
    "y = Variable(y_train[0:100], requires_grad=False) # No grad wrt to data \n",
    "w = Variable(torch.randn(D, K), requires_grad=True) # Grad wrt to weights!\n",
    "y_pred = softmax(x.mm(w))\n",
    "\n",
    "yours = softmax(x.mm(w)).data.numpy()\n",
    "correct = F.softmax(x.mm(w)).data.numpy()\n",
    "assert np.allclose(yours, correct, atol=0.01)\n",
    "\n",
    "yours = cross_entropy_loss(y_pred, y).data[0]\n",
    "correct = nn.CrossEntropyLoss()(x.mm(w), y).data[0]\n",
    "assert np.allclose(yours, correct, atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(lr=0.1, n_epochs=100, batch_size=100):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr: float\n",
    "        Learning rate used in SGD\n",
    "    n_epochs: int\n",
    "        Number of epochs to train\n",
    "    use_autograd: bool\n",
    "        If true will use PyTorch autograd\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w: np.array, shape: (D_in, D_out)\n",
    "        Found parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    n_epochs = 100\n",
    "    batch_size = 100\n",
    "    learning_rate = 0.1\n",
    "    use_autograd = True\n",
    "\n",
    "    # 784 + bias -> 10 model\n",
    "    D, K = 784 + 1, 10 \n",
    "\n",
    "    # Define all Variables used in the computation\n",
    "    dtype = torch.FloatTensor\n",
    "    x = Variable(torch.randn(batch_size, D).type(dtype), requires_grad=False) # No grad wrt to data\n",
    "    y = Variable(torch.randn(batch_size, K).type(dtype), requires_grad=False) # No grad wrt to data\n",
    "    w = Variable(torch.randn(D, K).type(dtype), requires_grad=True) # Grad wrt to weights!\n",
    "\n",
    "    loss_history = []\n",
    "    for epoch in tqdm.tqdm(range(n_epochs), total=n_epochs):    \n",
    "        for batch in range(len(x_train) // batch_size):\n",
    "            # Sample data\n",
    "            x_batch = x_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            y_batch = y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "\n",
    "            x_batch = Variable(x_batch.type(torch.FloatTensor), requires_grad=False)\n",
    "            y_batch = Variable(y_batch.type(torch.LongTensor), requires_grad=False)\n",
    "\n",
    "            y_pred = forward(x_batch, w)  # Hint: use forward\n",
    "            loss = cross_entropy_loss(y_pred, y_batch)  # Hint: cross_entropy_loss\n",
    "\n",
    "            if batch == 0:\n",
    "                loss_history.append(loss.data.numpy())\n",
    "\n",
    "            # Compute grad_w\n",
    "            loss.backward()\n",
    "            grad_w = w.grad  # Hint: use w.grad and backward. Google if needed.\n",
    "\n",
    "            # Update weights using gradient descent\n",
    "            w.data -= learning_rate * grad_w.data  # Hint: use learning rate and computed gradient\n",
    "\n",
    "            w.grad.data.zero_()  # You need to zero gradients, before next batch.  Google if needed.\n",
    "\n",
    "    plt.plot(loss_history)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "Each notebook will terminate with Tests section. This will automatically grade and assign points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 81.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "===========\n",
      "{'test1': 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAGwCAYAAAA9sLuaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncIPQAwC4QegBANz4/4V31H3NsCUMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08e8bc8c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = {}\n",
    "result['test1'] = int(evaluate(train_logistic_regression(n_epochs=100, lr=0.1)) > 0.6)\n",
    "print(\"Evaluation results:\\n===========\")\n",
    "print(result)\n",
    "json.dump(result, open(\"2b_pytorch.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn2018]",
   "language": "python",
   "name": "conda-env-nn2018-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
