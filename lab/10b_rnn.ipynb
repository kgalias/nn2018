{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RNNs: LSTM\n",
    "\n",
    "Goal of the lab is to:\n",
    "    * Understand and implement parts of LSTM\n",
    "    \n",
    "References:\n",
    "    * http://colah.github.io/posts/2015-08-Understanding-LSTMs/ (good ref. for the general equations)\n",
    "    * https://ytd2525.wordpress.com/2016/08/03/understanding-deriving-and-extending-the-lstm/ (more in depth journey through LSTM variants)\n",
    "    * http://nicodjimenez.github.io/2014/08/08/lstm.html (explains well constant error carousel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whiteboard exercises\n",
    "\n",
    "(Any left out exercise from the previous labs)\n",
    "\n",
    "* (0.5) Describe the main difference between GRU and LSTM. What is the intuition behind GRU? \n",
    "\n",
    "* (0.5) Describe the peephole connection variant of LSTM. What is the intuition behind peephole connection?\n",
    "\n",
    "* (0.5) Describe what is the \"shadow state\" in LSTM. See: https://ytd2525.wordpress.com/2016/08/03/understanding-deriving-and-extending-the-lstm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import torch\n",
    "from torch.nn import Module, Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline\n",
    "import json\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters (constant for the notebook)\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate\n",
    "DOWNLOAD_MNIST = True   # set to True if haven't download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A standard way to load a dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())\n",
    "# shape (2000, 28, 28) value in range(0,1)\n",
    "test_x = Variable(test_data.test_data, volatile=True).type(torch.FloatTensor)[:2000]/255.   \n",
    "test_y = test_data.test_labels.numpy().squeeze()[:2000]    # covert to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Code LSTM\n",
    "\n",
    "Reference: http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "Fill in the missing blanks. Train a single epoch, and save a plot of accuracy to ``10b_ex1.png``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTMCell(Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Note: parameters are initialized for you, but feel free to change this\n",
    "        # the suggested way of implementing forward is computing all inputs to\n",
    "        # gates at once by using a D -> 4*D linear layer\n",
    "        self.weight_ih = Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
    "        self.weight_hh = Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(4 * hidden_size))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, hx):\n",
    "        h, c = hx\n",
    "\n",
    "        # Compute input (i), forget (f), g (marked as \\tilde{C_t} in Colah), output (o),\n",
    "        # state (c) and hidden state (h)\n",
    "        # For reference see http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "        i = ??\n",
    "        f = ??\n",
    "        o = ??\n",
    "        g = ??\n",
    "        c = ??\n",
    "        h = ??\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM(Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, recurrent_size=None, bias=True, \n",
    "                 return_sequences=True, grad_clip=None):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.recurrent_size = recurrent_size\n",
    "        self.bias = bias\n",
    "        self.return_sequences = return_sequences\n",
    "        self.grad_clip = grad_clip\n",
    "\n",
    "        Cell = LSTMCell\n",
    "\n",
    "        kwargs = {'input_size': input_size,\n",
    "                  'hidden_size': hidden_size,\n",
    "                  'bias': bias,\n",
    "                  'grad_clip': grad_clip}\n",
    "\n",
    "        self.cell0 = Cell(**kwargs)\n",
    "        \n",
    "    def forward(self, input, initial_states=None):\n",
    "        if initial_states is None:\n",
    "            zeros = Variable(torch.zeros(input.size(0), self.hidden_size))\n",
    "            initial_states = [(zeros, zeros), ]\n",
    "\n",
    "        states = initial_states\n",
    "        outputs = []\n",
    "\n",
    "        # Note: Similar to code we wrote in 10a_rnn.\n",
    "        \n",
    "        time_steps = input.size(1)\n",
    "        for t in range(time_steps):\n",
    "            x = input[:, t, :]\n",
    "            hx = self.cell0(x, states[0])\n",
    "            states[0] = hx\n",
    "            x = hx[0]\n",
    "            outputs.append(hx)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            hs, cs = zip(*outputs)\n",
    "            h = torch.stack(hs).transpose(0, 1)\n",
    "            c = torch.stack(cs).transpose(0, 1)\n",
    "            output = (h, c)\n",
    "        else:\n",
    "            output = outputs[-1]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn = LSTM(28, 64, return_sequences=False)\n",
    "clf = nn.Linear(64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training and testing\n",
    "H = {\"acc\": []}\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):        # gives batch data\n",
    "        b_x = Variable(x.view(-1, 28, 28))              # reshape x to (batch, time_step, input_size)\n",
    "        b_y = Variable(y)                               # batch y\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        hidden, state = rnn.forward(b_x)\n",
    "        output = clf.forward(hidden)\n",
    "        loss = loss_func(output, b_y)\n",
    "        \n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            hidden, state = rnn.forward(test_x)\n",
    "            test_output = clf.forward(hidden)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "            accuracy = sum(pred_y == test_y.reshape(-1,)) / float(test_y.size)\n",
    "            H['acc'].append(accuracy)\n",
    "            print('train loss: %.4f' % loss.data[0], '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"LSTM\")\n",
    "plt.plot(H['acc'])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training accuracy\")\n",
    "plt.savefig(\"10b_ex1.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
