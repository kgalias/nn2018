{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: part 1, blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary ingredients to train a neural network are:\n",
    "    * model\n",
    "    * loss\n",
    "    * optimizer\n",
    "    \n",
    "    \n",
    "Your task will be to experiment with NN architecture solving FashionMNIST\n",
    "\n",
    "Goal is to:\n",
    "\n",
    "* Get familiar with torch.nn\n",
    "* Get intuition about how NN work\n",
    "* Get familiar with various basic building blocks\n",
    "* Understand overfitting/underfitting\n",
    "* Understand role of validation set\n",
    "\n",
    "When you are done, compile a simple pdf report (e.g. you can copy paste figures into a google doc, and save as a pdf) and put it into Dropbox folder. \n",
    "    \n",
    "<img width=400 src=\"https://github.com/gmum/nn2018/raw/master/lab/fig/4/smoothie.png\">\n",
    "\n",
    "Refs:\n",
    "\n",
    "* Great introduction to Convolutional networks: http://cs231n.github.io/convolutional-networks/\n",
    "* Interpreting neural networks: https://distill.pub/2018/building-blocks/\n",
    "* Playground used in the notebook: http://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from torch.autograd import gradcheck\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['figure.figsize'] = (7, 7)\n",
    "mpl.rcParams['axes.titlesize'] = 12\n",
    "mpl.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Get FashionMNIST (see 1b_FMNIST.ipynb for data exploration)\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Logistic regression needs 2D data\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# 0-1 normalization\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# Convert to Torch Tensor. Just to avoid boilerplate code later\n",
    "x_train = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "# Use only first 1k examples. Just for notebook to run faster\n",
    "x_valid, y_valid = x_train[1000:2000], y_train[1000:2000]\n",
    "x_train, y_train = x_train[0:1000], y_train[0:1000]\n",
    "x_test, y_test = x_test[0:1000], y_test[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaining intuition\n",
    "\n",
    "## DNN as building increasingly complex boundary\n",
    "\n",
    "There are many ways of thinking about DNNs, and it is important to develop an intuition. Developing intuition is one of the goals of this course. \n",
    "\n",
    "Go to http://playground.tensorflow.org/\n",
    "\n",
    "## Interpreting neurons\n",
    "\n",
    "Go to https://distill.pub/2018/building-blocks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=400 src=\"https://github.com/gmum/nn2018/raw/master/lab/fig/5/overfit1.png\">\n",
    "<img width=400 src=\"https://github.com/gmum/nn2018/raw/master/lab/fig/5/overfit2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting point\n",
    "\n",
    "This section gives basic model. Please adapt yourself training loop from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_simple_mlp(input_dim, output_dim):\n",
    "    model = torch.nn.Sequential()\n",
    "    model.add_module(\"linear_1\", torch.nn.Linear(input_dim, 512, bias=False))\n",
    "    model.add_module(\"nonlinearity_1\", torch.nn.Sigmoid())\n",
    "    model.add_module(\"linear_2\", torch.nn.Linear(512, output_dim, bias=False))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find architecture fitting XOR\n",
    "\n",
    "Go to http://playground.tensorflow.org/ and select second dataset.\n",
    "\n",
    "TODO: Improve this part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional networks\n",
    "\n",
    "We will have separate lab on convolutions. A crash course on CNNs:\n",
    "\n",
    "<img width=300 src=http://cs231n.github.io/assets/nn1/neural_net2.jpeg>\n",
    "\n",
    "<img width=400 src=http://cs231n.github.io/assets/cnn/stride.jpeg>\n",
    "\n",
    "CNN hyperparameters:\n",
    "\n",
    "* Number of filters\n",
    "* Filter size\n",
    "* Stride (less important usually)\n",
    "\n",
    "Ref: \n",
    "* Images from http://cs231n.github.io/convolutional-networks/\n",
    "* How to create CNNs in PyTorch https://github.com/vinhkhuc/PyTorch-Mini-Tutorials/blob/master/5_convolutional_net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP vs CNN\n",
    "\n",
    "Compare a good CNN (tune its hyperparameters on valid) to a good MLP (tune its hyperparameters on valid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN: effect of filter size\n",
    "\n",
    "Starting from a good CNN in previous section examine effect of filter size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth \n",
    "\n",
    "Starting from the basic MLP, examine effect of depth going from 1 to deepest you can on your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Width\n",
    "\n",
    "Starting from the basic MLP, examine effect of width, going to widest you can on your machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
