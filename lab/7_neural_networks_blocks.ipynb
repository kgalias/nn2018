{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical \"Neural Networking\": tuning NN on FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to:\n",
    "\n",
    "* Get familiar with various basic building blocks\n",
    "* Understand why we need train, valid and test split\n",
    "* Understand \"nuts and bolts\" of training DNNs\n",
    "\n",
    "When you are done, please compile a simple pdf report (e.g. you can copy paste figures into a google doc, and save as a pdf) and put it into Dropbox folder. \n",
    "\n",
    "Do a bunch of experiments, explain why something helps.\n",
    "\n",
    "Refs:\n",
    "\n",
    "* Nuts and bolts of applying Deep Learning: https://www.youtube.com/watch?v=F1ka6a13S9I\n",
    "* Introduction to Convolutional networks: http://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andrew Ng's \"Nuts and bolts\"\n",
    "\n",
    "Nuts and bolts of applying Deep Learning: https://www.youtube.com/watch?v=F1ka6a13S9I\n",
    "\n",
    "Some of them might sound very weird, but use as much as you can in this notebook. We will be coming back to them.\n",
    "\n",
    "Note: This is very likely to be an exam question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The general workflow\n",
    "\n",
    "Let's define overfitting for our purposes as achieving ~100% training accuracy (which is almost never possible to achieve on validation set).\n",
    "\n",
    "<img width=400 src=\"https://3.bp.blogspot.com/-duzBNDYdDGA/WFNtNi0DcNI/AAAAAAAAPSc/AHuvDXl6EhAgweD6IxGAbqOBK5qM_W05QCLcB/s1600/nuts-and-bolts-checklist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias vs variance\n",
    "\n",
    "\"It takes surprisingly long time to grok bias and variance deeply, but people that understand bias and variance deeply are often able to drive very rapid progress.\" --Andrew Ng \n",
    "\n",
    "TODO: Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use DNNs only when you have a lot of data\n",
    "\n",
    "Always use more data\n",
    "\n",
    "<img width=600 src=\"https://github.com/gmum/nn2018/raw/master/lab/fig/7/perf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of things we can tune\n",
    "\n",
    "* Add/remove blocks:\n",
    "    - Batch Normalization\n",
    "    - Dropout\n",
    "    - Convolution\n",
    "    - Pooling\n",
    "    - Dense\n",
    "    - Activation\n",
    "* Tune regularization\n",
    "    - Dropout\n",
    "    - L2\n",
    "* Alter parameters of blocks\n",
    "    - Number of units\n",
    "    - Nonlinearity type\n",
    "* Change optimization hyperparameters\n",
    "    - Learning rate\n",
    "    - Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from torch.autograd import gradcheck\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['figure.figsize'] = (7, 7)\n",
    "mpl.rcParams['axes.titlesize'] = 12\n",
    "mpl.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Get FashionMNIST (see 1b_FMNIST.ipynb for data exploration)\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Logistic regression needs 2D data\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# 0-1 normalization\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# Convert to Torch Tensor. Just to avoid boilerplate code later\n",
    "x_train = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "# Use only first 1k examples. Just for notebook to run faster\n",
    "x_valid, y_valid = x_train[1000:2000], y_train[1000:2000]\n",
    "x_train, y_train = x_train[0:1000], y_train[0:1000]\n",
    "x_test, y_test = x_test[0:1000], y_test[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting point\n",
    "\n",
    "This section gives basic model. Please adapt yourself training loop from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_simple_mlp(input_dim, output_dim):\n",
    "    model = torch.nn.Sequential()\n",
    "    model.add_module(\"linear_1\", torch.nn.Linear(input_dim, 512, bias=False))\n",
    "    model.add_module(\"nonlinearity_1\", torch.nn.Sigmoid())\n",
    "    model.add_module(\"linear_2\", torch.nn.Linear(512, output_dim, bias=False))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Our goal is to go through different types of blocks without very in-depth understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple tuning routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune MLP architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - regularize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune CNN architecture\n",
    "\n",
    "Compare a good CNN (tune its hyperparameters on valid) to a good MLP (tune its hyperparameters on valid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune architecture: CNN vs MLP\n",
    "\n",
    "We will have separate lab on convolutions. A crash course on CNNs:\n",
    "\n",
    "<img width=300 src=http://cs231n.github.io/assets/nn1/neural_net2.jpeg>\n",
    "\n",
    "<img width=400 src=http://cs231n.github.io/assets/cnn/stride.jpeg>\n",
    "\n",
    "CNN hyperparameters:\n",
    "\n",
    "* Number of filters\n",
    "* Filter size\n",
    "* Stride (less important usually)\n",
    "\n",
    "Ref: \n",
    "* Images from http://cs231n.github.io/convolutional-networks/\n",
    "* How to create CNNs in PyTorch https://github.com/vinhkhuc/PyTorch-Mini-Tutorials/blob/master/5_convolutional_net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune learning rate\n",
    "\n",
    "Starting from a good CNN in previous section examine effect of filter size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
